# -*- coding: utf-8 -*-
"""sieć_neuronowa_mnist

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1T6Ham7XRKMUUD40D_TeXBFPZUOIEODTt
"""

import torch
import torch.nn as nn
import torch.optim as optim
import torchvision.transforms as transforms
import torchvision.datasets as datasets
from torch.utils.data import DataLoader
import matplotlib.pyplot as plt
from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay
import numpy as np
from sklearn.metrics import mean_absolute_error

# Załadowanie danych MNIST
transform = transforms.Compose([
    transforms.ToTensor(),
    transforms.Normalize((0.5,), (0.5,))  # Normalizacja obrazów do zakresu (-1, 1)
])

train_dataset = datasets.MNIST(root='./data', train=True, download=True, transform=transform)
test_dataset = datasets.MNIST(root='./data', train=False, download=True, transform=transform)

train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)
test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)

# Definicja modelu sieci neuronowej dla MNIST
class MNISTClassifier(nn.Module):
    def __init__(self):
        super(MNISTClassifier, self).__init__()
        self.fc1 = nn.Linear(28 * 28, 128)
        self.fc2 = nn.Linear(128, 64)
        self.fc3 = nn.Linear(64, 10)  # 10 klas (cyfry od 0 do 9)
        self.relu = nn.ReLU()
        self.dropout = nn.Dropout(0.2)

    def forward(self, x):
        x = x.view(-1, 28 * 28)  # Spłaszczenie obrazu 28x28 do wektora
        x = self.relu(self.fc1(x))
        x = self.dropout(x)
        x = self.relu(self.fc2(x))
        x = self.fc3(x)
        return x


# Inicjalizacja modelu
model = MNISTClassifier()

# Funkcja kosztu i optymalizator
criterion = nn.CrossEntropyLoss()  # CrossEntropy dla klasyfikacji
optimizer = optim.Adam(model.parameters(), lr=0.001)

# Trening modelu
epochs = 10
train_loss_history = []
test_loss_history = []

for epoch in range(epochs):
    model.train()
    train_loss = 0.0
    for images, labels in train_loader:
        optimizer.zero_grad()
        outputs = model(images)
        loss = criterion(outputs, labels)
        loss.backward()
        optimizer.step()
        train_loss += loss.item()

    train_loss /= len(train_loader)
    train_loss_history.append(train_loss)

    # Ewaluacja na danych testowych
    model.eval()
    test_loss = 0.0
    correct = 0
    total = 0
    all_labels = []
    all_predictions = []
    with torch.no_grad():
        for images, labels in test_loader:
            outputs = model(images)
            loss = criterion(outputs, labels)
            test_loss += loss.item()

            _, predicted = torch.max(outputs, 1)
            correct += (predicted == labels).sum().item()
            total += labels.size(0)

            all_labels.extend(labels.numpy())
            all_predictions.extend(predicted.numpy())

    test_loss /= len(test_loader)
    test_loss_history.append(test_loss)
    accuracy = 100 * correct / total

    print(f"Epoch {epoch + 1}/{epochs}, Training Loss: {train_loss:.4f}, Test Loss: {test_loss:.4f}, Accuracy: {accuracy:.2f}%")

fig, axes = plt.subplots(1, 2, figsize=(16, 6))

# Wykres strat
axes[0].plot(range(1, epochs + 1), train_loss_history, label='Training Loss')
axes[0].plot(range(1, epochs + 1), test_loss_history, label='Test Loss')
axes[0].set_xlabel("Epoch")
axes[0].set_ylabel("Loss")
axes[0].set_title("Loss vs Epochs")
axes[0].legend()
axes[0].grid()

# Obliczenie macierzy konfuzji
conf_matrix = confusion_matrix(all_labels, all_predictions)
disp = ConfusionMatrixDisplay(confusion_matrix=conf_matrix, display_labels=range(10))

# Wizualizacja macierzy konfuzji
disp.plot(ax=axes[1], cmap='Blues', values_format='d')
axes[1].set_title("Confusion Matrix")

plt.tight_layout()
plt.show()

# Zwizualizowanie źle sklasyfikowanych wartości
misclassified = []
misclassified_labels = []
misclassified_preds = []

with torch.no_grad():
    for images, labels in test_loader:
        outputs = model(images)
        _, predicted = torch.max(outputs, 1)
        for i in range(len(labels)):
            if labels[i] != predicted[i] and len(misclassified) < 10:  # zbiera 10 wartości
                misclassified.append(images[i])
                misclassified_labels.append(labels[i].item())
                misclassified_preds.append(predicted[i].item())

# Plot - źle sklasyfikowanych wartości
plt.figure(figsize=(12, 8))
for idx, img in enumerate(misclassified):
    plt.subplot(2, 5, idx + 1)
    plt.imshow(img.squeeze(), cmap='gray')
    plt.title(f"True: {misclassified_labels[idx]}\nPredicted: {misclassified_preds[idx]}")
    plt.axis('off')
plt.tight_layout()
plt.show()

def calculate_mae(actual_labels, predicted_labels):
    return mean_absolute_error(actual_labels, predicted_labels)

# Obliczenie MAE na danych testowych po treningu
mae = calculate_mae(all_labels, all_predictions)
print(f"Mean Absolute Error (MAE) on Test Set: {mae:.4f}")